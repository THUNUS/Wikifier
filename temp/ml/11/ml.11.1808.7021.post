Starting from any initialisation will (eventually) get you to the same solution, but the number of iterations to converge will be different. In an earlier lecture, Prof Ng talked about feature scaling - to make all the features about the same size so as to converge faster. Starting with about equal weights is the other half of the same idea, you don't want there to one of your weighted features much larger than the other weighted features. If you have scaled the features to be the same size, then having weights of different sizes will unbalance again. Random initialisation gets you approximately equal weights, regular spacing does not.