Let's put it this way. Quantify the extent of the knowledge which you have.  Now quantify all the things you don't know.  You can't, So if you cannot quantify the extent of what you don't know, there is no way you can quantify the significance of what you do.

To provide a more practical example.  Take two twins.  One decides to sit on the couch all day, eat cake frosting and play video games.  The other jogs, does yoga, meditates, goes to church, and doesn't drink.  One day, while out jogging, the "healthy" twin gets shot in the head by a stray bullet.  Obviously, jogging killed him (predisposed him to being shot in the head).  Had he only been smart and sat on the couch with his twin eating cake frosting, he would be alive.  The universe of what you don't know doesn't care about what you do.  The prior likelihood of your existence is so infinitesimally small that technically, it really wouldn't matter if you were here or not.  The amount of specificity and detail in any model that accounts for you would have to be so great as to render the purpose of modeling it not worth the complexity in the first place.

However, if I can mimic you, then it means your existence is predefined, and it turns out it is probabilistic which means, that there is no future (I can prove that - tell me what the future is).  Therefore, there is only the temporal cross section probability of you (which is itself uncertain).  In other words, relative to anyone who knows you, there are more scenarios where you are than where you aren't. Thus mimicking your likelihood is important (cloning you).  Think of the jogging example in a much more prudent way.  When I start genetically sequencing you (proverbial), I can tell you what the probability of you dying of heart disease, cancer, etc. is.  It doesn't matter how much you jog.  You can't escape it.  No amount of prediction changes the future.  No amount of prediction tells you a genetic sequence.  Only imitation does.  Storing your information in quanta is what you're really concerned with.  Think of it like this: if I can build a machine that can imitate you so perfectly as to be completely indistinguishable from you (and as far as your decisions go, I can), then what is free will?  If I can do that then what is time? (Why can't I just store you in a machine, turn it off, and then ship you a distance -let's say a stellar distance- and then turn you back on.  You've gone a distance without the effect of time; then what is distance?  Then what is time?  I may sound philosophical, but to me it seems like everyone else who talks about the "future" can't see that the emperor has no clothes.

I mean really, to assume that you can predict what will happen next presumes that something will happen next.  "Next" exists between 0 and 1, but good luck proving either 0 or 1 (which is a required assumption to prediction).  It seems to me that utility is only to be gained when these arbitrary definitions of supervised and unsupervised learning techniques are done away with (they pose an incorrect question, analogous to "Have you stopped beating your wife yet.")  The question cannot be answered because the conditions of the question do not match reality.  That's what I'm saying about the "supervised" or "unsupervised".  Another good example is in Zen and the Art of Motorcycle Maintenance:

"For example, it's stated over and over again that computer circuits exhibit only two states, a voltage for "one" and a voltage for "zero." That's silly! Any computer-electronics technician knows otherwise. Try to find a voltage representing one or zero when the power is off! The circuits are in a mu state."

So perhaps instead of saying that I'm too philosophical, you might revisit the assumptions of your models.  The emperor has no clothes.  The answer to the video should be "n.a."