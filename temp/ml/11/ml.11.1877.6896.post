I don't understand why the gradient checking step is much slower. Think of a neural network of three layers. 
The number of nodes in each layer is denoted as $$a,b,c$$. Then the back-propagation algorithm and gradient
checking both use $$O(m(ab+bc))$$ time where $$m$$ is the number of training examples. 