Why not train until you get something acceptable? If there comes a point where further training doesn't seem to help, consider trying a new model or debugging. As Prof. Ng, all too often Machine Learnists think that getting more data will help remedy bad algorithms, but I'm saying to continue training a **good** one and see where that takes you. I'd imagine all the debugging techniques we were taught are really only necessary for accuracy rates that are much lower than 95%. As an example, the video of the robotic car at CMU had to be trained for two months to be safe enough to put on the road. Same scenario.

Actually, I wouldn't be suprised if debugging first would actually be a more economical approach. You could rule out overfitting/model problems quickly and have that give insight into whether further training is valuable.