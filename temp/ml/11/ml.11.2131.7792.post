With high bias the amount of training examples doesn't change the cost much because of the $$1/m$$ term; think of the cost function as the average error (it isn't really that, but it does behave similarly in this case). If you have high bias, the cost would increase with each training example only if each new training example would be further away from hypothesis than the previous example. In other words, cost would change only if new examples would come from some completely new pattern than previous examples.

The gap is low because the hypothesis underfits the training set in the first place. You can assume that the training and cross-validation data are generated by the same process (they come from the same distribution), so the cross-validation set contains the same pattern as your training set. Since a hypothesis with high bias underfits the pattern you're trying to fit, slight variation between training and cross-validation set won't change the cost function much.

Imagine a pattern of point distribution on a 2D plane. Now try to fit a line to it. Replace the points with a set of different points that recreate the same pattern -- your line roughly still fits the new set of points as best as it can, thus the cost increases only slightly.

The inverse is true for high variance problem (overfitting). Here your hypothesis makes an exaggerated guess about the pattern of your data; it models a pattern that is purely coincidental (only visible in this particular set of examples). So new examples will make the cost much higher because they don't fit the exaggerated hypothesis at all. Here you can imagine some really wild polynomial curve that jumps up and down between data points. If you place a new point somewhere in the cloud of existing points (e.g. between two existing points), it will be far away from your hypothesis curve, which goes too high or too low at that interval. Such wild curves are caused by large parameters, and that's where the regularization comes in.