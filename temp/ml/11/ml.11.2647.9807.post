Professor Ng said that neural networks behave well even without bias nodes, but that we use them for convention. This is completely false if you care about the probabilities output by your network.

I have been using a neural net for some research I'm doing, and have had an annoying bug. The network always made good predictions, but its probabilities were all very close to 0.5. Events that never occurred even once in the training set were being predicted with probabilities of nearly 0.5, and the event that the neural net should have been able to tell would occur with near certainty were only being predicted with a probability slightly greater than 0.5. The problem turned out to be that I was regularizing the bias nodes' outputs as well as those of other nodes. This causes the bias nodes to have restricted influence on the inputs to all sigmoid functions, resulting in inputs that stay close to 0. Sigmoid of 0 is 0.5. If you want reasonable probabilities to be outputted by your neural net, use bias nodes and do not regularize them.