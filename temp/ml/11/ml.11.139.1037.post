Most of these answers seem to be focused around the mechanics of finding a minima. This actually has nothing to do with why least squares is the most commonly used loss function for regression. For a given data set the parameters that minimises the loss function will, in principle, be different for different costs functions. The parameters that minimise a sum of squares error will in general be different to those that minimise a sum of absolute errors cost function. So it's not about which makes it easier to put into an algorithim, because they actually give you different answers. That question then is which is right?

It turns out there is a very clear answer from theory, and the answer is least squares. It comes about because 'real' data always has noise. That noise could be a sampling error i.e you ask 1000 people out of a population of 100 million who they are going to vote for, from this you get an estimate, with an error distribution, of who will win the election. The noise could be a measurement error, i.e. you measure the voltage in a wire but your voltmeter is only so accurate. For details I won't go into (Rik Jansen's reply gives some pointers of where to start reading) it turns out that most errors in real data tend to follow the classic 'Bell Curve' known in some circles as a Gaussian distribution, or a Normal distribution. When you have a bunch of data with errors drawn from such a distribution it turns out that you are most likely to find the 'correct' underlying model if you seek to minimise the sum of squares errors. Not the sum of absolute errors or cubes of errors or logs of errors but the sum of squares.

This is why we tend to minimise the sum of squares, it has nothing at all to do with algorithmic convenience and everything to do with finding a model that is most likely to actually reflect the process that has produced the data that we want to make predictions about. There are many important cases where this is not the ideal loss function to use, but even then the improved loss function is usually a modification to cope with things such as correlations between the errors or to avoid parameters that seem to fit the data but we know for other reasons cannot be correct (in technical language we have 'prior' information that we want to use). In generall though, you usually can't go too far wrong using least squares. The issue of how to implement an efficient algorithm to do the minimisation is a seperate question.