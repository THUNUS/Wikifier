Yes, the cost will be increasing with first few examples, but after enough data points the cost will remain almost the same, unless new points come from a completely different pattern. Check out [law of large numbers](https://en.wikipedia.org/wiki/Law_of_large_numbers). This is not directly related to the cost function, but I think it might give you some intuition. It is also worth noting that as the set size goes to infinity, the cost for two different sets becomes equal (in a perfect world). This is somewhat related to the law of large numbers, since the cost will essentially reach its expected value for that particular data distribution of both sets.  
I also recommend you to play with this in Octave; print the cost at different training set size. You will see that adding new examples to an already reasonably sized training set won't change the cost much. Even better, plot the cost function for each new training example. Make sure your hypothesis underfits though.

About the gap; but that's the thing -- there is a slight variance between training set and cross-validation set, so the high-bias hypothesis also has slight cost difference for both sets, ergo the gap between training and cross-validation cost is small. Note that we're not talking about variance of new examples here, but about variance of whole different sets of examples.  
And the same holds for high variance problem. Your hypothesis captures a pattern that isn't really there in general, but only in the training set. So the hypothesis will completely misfit some new set compared to the training set and the cost difference or "the gap" will be large.